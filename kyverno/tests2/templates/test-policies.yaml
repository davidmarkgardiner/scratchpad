apiVersion: v1
kind: Namespace
metadata:
  name: at54321-prod
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: policy-test-runner
  namespace: at54321-prod
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: policy-test-runner-{{ .Release.Name }}
rules:
- apiGroups: [""]
  resources: ["namespaces", "pods", "services"]
  verbs: ["create", "delete", "get", "list"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["create", "delete", "get", "list"]
- apiGroups: ["networking.k8s.io"]
  resources: ["networkpolicies"]
  verbs: ["get", "list"]
- apiGroups: ["security.istio.io"]
  resources: ["peerauthentications"]
  verbs: ["create", "delete", "get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: policy-test-runner-{{ .Release.Name }}
subjects:
- kind: ServiceAccount
  name: policy-test-runner
  namespace: at54321-prod
roleRef:
  kind: ClusterRole
  name: policy-test-runner-{{ .Release.Name }}
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: v1
kind: Pod
metadata:
  name: "{{ .Release.Name }}-test-pod-security"
  namespace: at54321-prod
  labels:
    app.kubernetes.io/name: policy-tests
  annotations:
    "helm.sh/hook": test
spec:
  automountServiceAccountToken: false
  securityContext:
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
  serviceAccountName: policy-test-runner
  containers:
  - name: test
    image: bitnami/kubectl:1.28.4
    securityContext:
      allowPrivilegeEscalation: false
      privileged: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      runAsUser: 1001
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: kube-api-access
      mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      readOnly: true
    - name: test-results
      mountPath: /results
    command: ["/bin/bash", "-c"]
    args:
      - |
        set -x
        exec 1> >(tee /results/output.log)
        exec 2> >(tee /results/error.log)
        
        echo "Testing Pod Security Policy..."
        
        # Test privileged container block
        echo "Testing privileged pod creation (should be blocked)..."
        POD_OUTPUT=$(kubectl run test-priv --image=nginx:1.25.3 --privileged -n at54321-prod 2>&1)
        POD_EXIT=$?
        echo "Pod creation output: $POD_OUTPUT"
        if [ $POD_EXIT -ne 0 ]; then
          echo "✅ Privileged pod was correctly blocked"
        else
          echo "ERROR: Privileged pod was created when it should have been blocked!"
          kubectl delete pod test-priv -n at54321-prod
          exit 1
        fi
        
        # Test app security context requirements
        echo "Testing deployment with privileged security context (should be blocked)..."
        echo "Creating test deployment..."
        DEPLOY_OUTPUT=$(cat <<EOF | kubectl apply -f - 2>&1
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: test-security
          namespace: at54321-prod
          labels:
            app.kubernetes.io/name: test-security
        spec:
          selector:
            matchLabels:
              app: test
          template:
            metadata:
              labels:
                app: test
                app.kubernetes.io/name: test-security
            spec:
              automountServiceAccountToken: false
              securityContext:
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              containers:
              - name: nginx
                image: nginx:1.25.3
                securityContext:
                  privileged: true
                  allowPrivilegeEscalation: true
                  readOnlyRootFilesystem: true
                  runAsNonRoot: true
                  seccompProfile:
                    type: RuntimeDefault
                  runAsUser: 101
        EOF
        )
        DEPLOY_EXIT=$?
        echo "Deployment creation output: $DEPLOY_OUTPUT"
        echo "Deployment creation exit code: $DEPLOY_EXIT"
        
        echo "Checking if deployment exists..."
        GET_OUTPUT=$(kubectl get deployment test-security -n at54321-prod 2>&1)
        GET_EXIT=$?
        echo "Get deployment output: $GET_OUTPUT"
        if [ $GET_EXIT -ne 0 ]; then
          echo "✅ Privileged deployment was correctly blocked"
        else
          echo "ERROR: Deployment with privileged security context was created when it should have been blocked!"
          kubectl describe deployment test-security -n at54321-prod
          kubectl delete deployment test-security -n at54321-prod
          exit 1
        fi
        
        echo "✅ Pod Security Policy tests passed"
        
        # Keep the pod running so we can check the logs
        sleep 30
  volumes:
  - name: tmp
    emptyDir: {}
  - name: test-results
    emptyDir: {}
  - name: kube-api-access
    projected:
      sources:
      - serviceAccountToken:
          expirationSeconds: 3600
          path: token
      - configMap:
          name: kube-root-ca.crt
          items:
          - key: ca.crt
            path: ca.crt
      - downwardAPI:
          items:
          - path: namespace
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
  restartPolicy: Never
---
apiVersion: v1
kind: Pod
metadata:
  name: "{{ .Release.Name }}-test-resource-requirements"
  namespace: at54321-prod
  labels:
    app.kubernetes.io/name: policy-tests
  annotations:
    "helm.sh/hook": test
spec:
  automountServiceAccountToken: false
  securityContext:
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
  serviceAccountName: policy-test-runner
  containers:
  - name: test
    image: bitnami/kubectl:1.28.4
    securityContext:
      allowPrivilegeEscalation: false
      privileged: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      runAsUser: 1001
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: kube-api-access
      mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      readOnly: true
    - name: test-results
      mountPath: /results
    command: ["/bin/bash", "-c"]
    args:
      - |
        set -x
        exec 1> >(tee /results/output.log)
        exec 2> >(tee /results/error.log)
        
        echo "Testing Resource Requirements Policy..."
        # Test deployment without resource limits
        echo "Creating deployment without resource limits (should be blocked)..."
        DEPLOY_OUTPUT=$(cat <<EOF | kubectl apply -f - 2>&1
        apiVersion: apps/v1
        kind: Deployment
        metadata:
          name: test-resources
          namespace: at54321-prod
          labels:
            app.kubernetes.io/name: test-resources
        spec:
          selector:
            matchLabels:
              app: test
          template:
            metadata:
              labels:
                app: test
                app.kubernetes.io/name: test-resources
            spec:
              automountServiceAccountToken: false
              securityContext:
                runAsNonRoot: true
                seccompProfile:
                  type: RuntimeDefault
              containers:
              - name: nginx
                image: nginx:1.25.3
                securityContext:
                  allowPrivilegeEscalation: false
                  privileged: false
                  readOnlyRootFilesystem: true
                  runAsNonRoot: true
                  seccompProfile:
                    type: RuntimeDefault
                  runAsUser: 101
        EOF
        )
        DEPLOY_EXIT=$?
        echo "Deployment creation output: $DEPLOY_OUTPUT"
        echo "Deployment creation exit code: $DEPLOY_EXIT"
        
        echo "Checking if deployment exists..."
        GET_OUTPUT=$(kubectl get deployment test-resources -n at54321-prod 2>&1)
        GET_EXIT=$?
        echo "Get deployment output: $GET_OUTPUT"
        if [ $GET_EXIT -ne 0 ]; then
          echo "✅ Deployment without resource limits was correctly blocked"
        else
          echo "ERROR: Deployment without resource limits was created!"
          kubectl describe deployment test-resources -n at54321-prod
          kubectl delete deployment test-resources -n at54321-prod
          exit 1
        fi
        
        echo "✅ Resource Requirements Policy test passed"
        
        # Keep the pod running so we can check the logs
        sleep 30
  volumes:
  - name: tmp
    emptyDir: {}
  - name: test-results
    emptyDir: {}
  - name: kube-api-access
    projected:
      sources:
      - serviceAccountToken:
          expirationSeconds: 3600
          path: token
      - configMap:
          name: kube-root-ca.crt
          items:
          - key: ca.crt
            path: ca.crt
      - downwardAPI:
          items:
          - path: namespace
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
  restartPolicy: Never
---
apiVersion: v1
kind: Pod
metadata:
  name: "{{ .Release.Name }}-test-spot-config"
  namespace: at54321-prod
  labels:
    app.kubernetes.io/name: policy-tests
  annotations:
    "helm.sh/hook": test
spec:
  automountServiceAccountToken: false
  securityContext:
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault
  serviceAccountName: policy-test-runner
  containers:
  - name: test
    image: bitnami/kubectl:1.28.4
    securityContext:
      allowPrivilegeEscalation: false
      privileged: false
      readOnlyRootFilesystem: true
      runAsNonRoot: true
      seccompProfile:
        type: RuntimeDefault
      runAsUser: 1001
    volumeMounts:
    - name: tmp
      mountPath: /tmp
    - name: kube-api-access
      mountPath: /var/run/secrets/kubernetes.io/serviceaccount
      readOnly: true
    - name: test-results
      mountPath: /results
    command: ["/bin/bash", "-c"]
    args:
      - |
        set -x
        exec 1> >(tee /results/output.log)
        exec 2> >(tee /results/error.log)
        
        echo "Testing Spot Configuration Policy..."
        # Create test deployment
        echo "Creating test deployment..."
        DEPLOY_OUTPUT=$(kubectl create deployment test-spot --image=nginx:1.25.3 -n at54321-prod 2>&1)
        DEPLOY_EXIT=$?
        echo "Deployment creation output: $DEPLOY_OUTPUT"
        echo "Deployment creation exit code: $DEPLOY_EXIT"
        
        echo "Waiting for deployment to be mutated..."
        sleep 5
        
        # Verify spot tolerations and affinity
        echo "Checking deployment configuration..."
        DEPLOYMENT_YAML=$(kubectl get deployment test-spot -n at54321-prod -o yaml)
        if ! echo "$DEPLOYMENT_YAML" | grep -q "kubernetes.azure.com/scalesetpriority"; then
          echo "ERROR: Spot toleration not added!"
          exit 1
        fi
        if ! echo "$DEPLOYMENT_YAML" | grep -q "nodeAffinity"; then
          echo "ERROR: Node affinity not added!"
          exit 1
        fi
        
        echo "Cleaning up..."
        kubectl delete deployment test-spot -n at54321-prod
        echo "✅ Spot Configuration Policy test passed"
        
        # Keep the pod running so we can check the logs
        sleep 30
  volumes:
  - name: tmp
    emptyDir: {}
  - name: test-results
    emptyDir: {}
  - name: kube-api-access
    projected:
      sources:
      - serviceAccountToken:
          expirationSeconds: 3600
          path: token
      - configMap:
          name: kube-root-ca.crt
          items:
          - key: ca.crt
            path: ca.crt
      - downwardAPI:
          items:
          - path: namespace
            fieldRef:
              apiVersion: v1
              fieldPath: metadata.namespace
  restartPolicy: Never
---
apiVersion: batch/v1
kind: Job
metadata:
  name: "{{ .Release.Name }}-cleanup"
  namespace: policy-validation
  annotations:
    "helm.sh/hook": post-test
    "helm.sh/hook-delete-policy": hook-succeeded
spec:
  template:
    spec:
      serviceAccountName: policy-test-runner
      containers:
      - name: cleanup
        image: bitnami/kubectl:latest
        command: ["/bin/bash", "-c"]
        args:
        - |
          kubectl delete ns policy-validation --ignore-not-found
          kubectl delete clusterrole policy-test-runner-{{ .Release.Name }} --ignore-not-found
          kubectl delete clusterrolebinding policy-test-runner-{{ .Release.Name }} --ignore-not-found
      restartPolicy: Never 